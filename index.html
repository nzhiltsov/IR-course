<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Курс по информационному поиску - Высшая школа ИТИС КФУ (Весна 2016) by nzhiltsov</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">Information Retrieval</h1>
        <p class="header">Страница курса по информационному поиску в Высшей школе ИТИС КФУ</p>
      </header>
      <section>
        <h3>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Основы информационного поиска (Весна 2016)</h3>

<p>На данной странице приведены основные материалы, которые помогут успешно подготовиться к практическим заданиям и экзамену.</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Преподаватели</h3>

<p><a href="https://github.com/nzhiltsov" class="user-mention">Никита Жильцов</a> - лекции<br/>Владислав Бойко - практика</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Слайды</h3>

<p>
<ol><li>Лекция 1: Основы информационного поиска, структура инвертированного индекса [<a href="http://slides.com/nikitazhiltsov/ir-course-lecture-1-basics?token=9Qi8EKAD4J4vHZyjzZzDmyPqmgQr">Слайды</a>]</li>
<li>Лекция 2: Алгоритмы индексирования, сжатие индекса [<a href="http://slides.com/nikitazhiltsov/ir-course-lecture-2-index-construction-compression?token=fZDdinE-">Слайды</a>]</li>
<li>Лекция 3: Ранжирование в векторной модели документа [<a href="http://slides.com/nikitazhiltsov/ir-course-lecture-3-vector-space-model">Слайды</a>]</li>
<li>Лекция 4: Вероятностные модели поиска и языковое моделирование [<a href="http://slides.com/nikitazhiltsov/deck">Слайды</a>]</li>
<li>Лекция 5: Оценивание результатов поиска [<a href="http://slides.com/nikitazhiltsov/ir-course-lecture-5-evalution-of-ir">Слайды</a>]</li>
<li>Лекция 6: Машинное обучение ранжированию [<a href="http://slides.com/nikitazhiltsov/ir-course-lecture-6-learning-to-rank">Слайды</a>]</li>
<li>Лекция 7: Ранжирование структурированных документов [<a href="https://slides.com/nikitazhiltsov/ircourse-lecture-7-structured-document-retrieval">Слайды</a>]</li>
</ol>

<p>
<ol><li>Практика 1: Знакомство с Elastic Search [<a href="Practice-1.pptx">Слайды</a>]</li>
</ol>
<ol><li>Практика 2: Поисковые команды [<a href="Practice-1.pptx">Слайды</a>]</li>
</ol>
</p>
</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Программа экзамена</h3>

<ol>
<li>Основные компоненты инвертированного индекса</li>
<li>Алгоритмы пересечения словопозиций: основной, общий, с пропусками</li>
<li>Координатный индекс: структура, алгоритм пересечения словопозиций</li>
<li>Блочное индексирование, основанное на сортировке</li>
<li>Однопроходное индексирование в оперативной памяти</li>
<li>Распределенное индексирование с MapReduce</li>
<li>Законы Хипса и Ципфа</li>
<li>Способы хранения словаря без сжатия: массив, строка, блок</li>
<li>Сжатие словаря фронтальным кодированием</li>
<li>Сжатие словопозиций кодированием переменной длины</li>
<li>Сжатие словопозиций: гамма коды</li>
<li>Векторная модель документа: взвешивание по TF-IDF</li>
<li>Ранжирование в векторной модели документа (формула косинуса, базовый алгоритм)</li>
<li>Опорная нормировка по длине документа</li>
<li>Бинарная модель независимости: вывод функции ранжирования</li>
<li>Бинарная модель независимости: оценки по методу максимального правдоподобия</li>
<li>Бинарная модель независимости: оценивание через обратную связь по релевантности</li>
<li>BM25: смесь пуассоновских распределений, формула ранжирования</li>
<li>Языковые модели: определение, пример, применение для поиска</li>
<li>Языковые модели: оценка по методу максимального правдоподобия, сглаживание Елинека-Мерсера, сглаживание Дирихле</li>
<li>Меры оценивания качества без ранжирования. Кривая точность-полнота</li>
<li>Средняя точность по 11 точкам. Макроусредненная средняя точность (mean average precision, MAP)</li>
<li>Нормированная дисконтированная совокупная выгода (normalized discounted cumulative gain, NDCG)</li>
<li>Постановка задачи машинного обучения ранжированию. Три подхода: поточечный, попарный, списочный</li>
<li>Метод опорных векторов: линейная разделимость классов, опорные векторы, линейный классификатор</li>
<li>Метод опорных векторов: геометрический зазор, задача оптимизации</li>
<li>Метод опорных векторов: классификация с мягким зазором</li>
<li>Метод опорных векторов для ранжирования (Ranking SVM)</li>
<li>BM25F: некорректная и корректная комбинация весов полей</li>
<li>MLM: смесь вероятностных языковых моделей</li>
<li>PRMS (Probabilistic retrieval model for semi-structured data)</li>
</ol>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Тестовые коллекции</h3>

<ul>
<li><a href="http://www.search-engines-book.com/collections/">Search Engines: Information Retrieval in Practice</a></li>
<li><a href="https://dumps.wikimedia.org/">Снэпшоты Википедии</a></li>
<li>РОМИП: <a href="http://romip.ru/relevance-tables/ru/index.html">таблицы релевантности</a>, <a href="http://romip.ru/ru/collections/format-docs.html">описание формата</a></li>
<li><a href="http://krisztianbalog.com/resources/sigir-2013-dbpedia/">DBpedia</a> (коллекция, запросы, оценки релевантности)</li>
</ul>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Практические задания</h3>

<p>
<ol><li>Необходимо составить списки стоп-слов на основе статистики терминов в коллекции по трем разным коллекциям документов. Стоп-словами будут считаться 5% самых частотных и 5% наименее частотных (по документной частоте, document frequency=df) терминов из индекса. Предобработка коллекции должна включать основные операции, такие как перевод в нижний регистр и стемминг. </li>
<li>Для данной коллекции построить графики распределений, иллюстрирующие законы Ципфа и Хипса. Графики должны содержать кривые, построенные по коллекции, и прямые, параметризуемые этими законами и построенными с помощью метода наименьших квадратов.</li>
<li>Реализовать сжатие словаря фронтальным кодированием. В реализуемой структуре данных для каждого термина должны храниться значения документной частоты, указатели на списки словопозиций, указатели терминов. Необходимо реализовать поиск термина (term lookup): по данному термину найти его документную частоту. Апробировать на тестовой коллекции.</li>
<li>Реализовать сжатие файла словопозиций кодированием переменной длины (variable byte encoding). Апробировать на тестовой коллекции.</li>
<li>Реализовать вариант функции ранжирования tf-idf - модель с опорной нормировкой (pivoted document length normalization). <img src="pivoted_document_length_model.png" alt="модель с опорной нормировкой" width="80%"/>, где D - документ, Q - запрос, tf(t,D) - частота термина t в документе D, |D| - длина документа D, avdl - средняя длина документа, tf(t,Q) - частота термина t в запросе, N - количество документов в коллекции, df(t) - документная частота термина t, s - параметр в диапазоне [0,1]. Апробировать на тестовой коллекции.</li> 
<li>Реализовать варианты функции ранжирования tf-idf с разным масштабированием документной частоты. См. рис.<br/> <img src="document_frequency_scaling.png" alt="масштабирование документной частотности" width=50%"/><br/>Апробировать на тестовой коллекции.</li>
<li>Реализовать языковую модель, основанную на линейной интерполяции (сглаживание Елинека-Мерсера), при которой вероятность сгенерировать термин t из документа d оценивается как смесь (линейная комбинация) распределений вероятностей термина по документу и по коллекции. См. формулу.<br/> <img src="jelinek_mercer_smoothing.png" alt="языковая модель, основанная на линейной интерполяции" width="70%"/><br/>Апробировать на тестовой коллекции.</li>
<li>Реализовать подсчет основных мер оценивания: точность на уровне k (P@k), макроусредненная средняя точность на уровне k (MAP@k), <a href="http://en.wikipedia.org/wiki/Mean_reciprocal_rank">mean reciprocal rank</a> (MRR). Протестировать результаты с помощью коллекции CACM (см. п. "Тестовые коллекции") и оценок релевантности (relevance judgments), генерируя поисковую выдачу случайным образом смешивая релевантные и неоцененные результаты (эмуляция некоторой функции ранжирования). Сравнить полученные оценки с результатами инструмента оценивания от TREC: <a href="http://trec.nist.gov/trec_eval/">trec_eval</a>.</li>
<li>Провести оптимизацию параметра регуляризации (C) линейной модели обучения ранжированию <a href="http://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html">SVM-rank</a> (linear kernel) в схеме пятиблочного скользящего контроля (5-fold cross validation). В качестве тестовой коллекции можно взять DBpedia (см. п. "Тестовые коллекции") с оценками релевантности. В качестве целевой меры - усредненную среднюю точность (MAP@k). Привести оценки качества поиска для разных параметров с макроусреднением по 5 блокам. Меры оценивания можно считать с помощью инструмента <a href="http://trec.nist.gov/trec_eval/">trec_eval</a>. Признаки - на свое усмотрение (примеры: косинусная мера, длина документа в лексемах, длина запроса, значение BM25 и т.п.)</li>
</ol>
</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Оценка</h3>

<table style="width:100%">
<tr>
    <th>Части курса</th>
    <th>Баллы</th> 
    <th>Дата сдачи</th>
  </tr>
  <tr>
    <td>Практические задания</td>
    <td>30%</td>		
    <td>2 апреля</td>
  </tr>
  <tr>
    <td>Проект</td>
    <td>20%</td>		
    <td>6 апреля (группы 201, 202, 203) и <br> 9 апреля (группы 204,205,207)</td>
  </tr>
  <tr>
    <td>Экзамен</td>
    <td>50%</td>		
    <td>c 12 апреля</td>
  </tr>
</table>

Студенты, получившие не менее 45 баллов за практические задания и проект, получают экзамен (50 баллов) автоматом.

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Рекомендованная литература</h3>

<p>
<ol>
<li>К. Маннинг, П. Рагхаван, Х.Шютце. Введение в информационный поиск. Пер. с англ. - М.: ООО "И.Д. Вильямс", 2011. - 528 с. (Основной учебник).</li>
<li>Tie-Yan Liu. Learning to Rank for Information Retrieval. Springer, 2011.</li>
<li>S. Amit, C. Buckley, M. Mitra. Pivoted document length normalization // In Proc. SIGIR, pp. 21–29. ACM Press. (1996) URL: <a href="http://dspace.library.cornell.edu/bitstream/1813/7217/1/95-1560.pdf">http://dspace.library.cornell.edu/bitstream/1813/7217/1/95-1560.pdf</a>.</li>
<li>J. Zobel, A. Moffat. Exploring the similarity space // ACM SIGIR Forum. Vol. 32. No. 1. ACM, 1998. URL: <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.6193&rep=rep1&type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.6193&rep=rep1&type=pdf</a></li>
<li>S. Robertson, S. Walker. Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval // Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval. Springer-Verlag. New York, Inc., 1994. URL: <a href="http://nclt.computing.dcu.ie/~gjones/Teaching/CA437/p232.pdf">http://nclt.computing.dcu.ie/~gjones/Teaching/CA437/p232.pdf</a></li>
<li>M. Smucker, J. Allan, and B. Carterette. A Comparison of Statistical Significance Tests for Information Retrieval Evaluation // In Proceedings of the 16th ACM CIKM, pages 623–632, 2007. URL: <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.366.7734&rep=rep1&type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.366.7734&rep=rep1&type=pdf</a></li>
</p>	

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Идеи для проектов</h3>

<h4>Приложения</h4>

<ol><li><a href="https://ru.wikipedia.org/wiki/%D0%92%D0%B5%D1%80%D1%82%D0%B8%D0%BA%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%BF%D0%BE%D0%B8%D1%81%D0%BA">Вертикальный поиск</a> по <a href="http://kpfu.ru">сайту нашего университета</a>: подразделение (см. <a href="http://kpfu.ru/structure">список</a>), сотрудники (<a href="http://kpfu.ru/main?p_id=10076&p_lang=&p_pub_type=20&p_type=9">пример страницы</a>), конкурсы/программы/гранты (см. <a href="http://kpfu.ru/international/proekty-i-granty/otkrytye-konkursy/arhiv">страницу</a>). Система должна автоматически определять тип запрашиваемой страницы в запросе по ключевым словам. Пример эвристики - если в запросе упоминается имя, возвращать релевантные страницы о сотруднике (а не произвольные страницы, на которых упоминается данное имя). </li>
<li>Отслеживание товара (задается ключевыми словами, например, "телевизор большая диагональ") в агрегаторе <a href="https://tech.yandex.ru/market/content/">Яндекс.Маркет.</a> Индекс периодически обновляется. Учесть свежесть результатов при ранжировании.</li>
<li>Поиск по пабликам КФУ и ИТИСа ВКонтакте: по упоминаниям людей в сообщениях, авторам сообщений и тексту сообщения (например, "петя иванов студвесна"). Можно использовать <a href="https://vk.com/dev/openapi">API ВКонтакте</a>. Выделять термины в запросе, обозначающие имя, и придать им больший вес в ранжирующей функции.</li>
<li>Поиск твитов (см. <a href="https://dev.twitter.com/rest/public">Twitter API</a>). Придумать новую ранжирующую функцию, которая бы учитывала: появление ключевого слова как обычного слова, упоминания пользователя и в виде хэштэга; нормализацию по длине. Кроме того, обратить внимание на предобработку - разбиение на лексемы.</li>
<li>Поиск упоминаний компаний в новостях. Можно взять RSS ленту с пресс-релизами о компаниях, например, <a href="http://firrma.ru/data/rss/">Firrma</a>. На стадии индексирования компании можно выделять из некоторого готового словаря (возможно, с алиасами - эквивалентными наименованиями, например, "Российские технологии"="Ростех"). В поисковом интерфейсе вводятся ключевые слова, обозначающие компанию, и, возможно, уточняющие термины (например, "ростех выручка"). Система возвращает релевантные новости. Учесть различное взвешивание терминов в запросе.</li>

</ol>	


<h4>Темы исследований</h4>
<ol>
<li>Провести сравнительную экспериментальную оценку различных ранжирующих функций на основе разных вариантов взвешивания TF-IDF для некоторых тестовых коллекций (как минимум две). Взять в качестве основы (baseline) - классическую схему взвешивания TF-IDF. Привести значения основных мер оценивания (MAP@100, P@10, P@20, MRR, NDCG@100) и процент относительного улучшения по сравнению с основой. Посчитать статистическую значимость по тесту Фишера. Сделать выводы.</li>
<li>Провести аналогичное исследование (см. 1). Сравнить только BM25 и query likelihood language model (Dirichlet smoothing). Оптимизировать параметры модели BM25 в схеме пятиблочного скользящего контроля. Сделать выводы.</li>
<li>Придумать статические и динамические характеристики документов (см. Лекция 3). Исследовать их значимость (в смысле качества поисковых результатов) по схеме leave-one-out для модели обучения ранжированию SVM-rank. Привести результаты, как минимум, на двух тестовых коллекциях. Сделать выводы.</li>
</ol>
  </body>
</html>
