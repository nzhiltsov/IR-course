<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Курс по информационному поиску ИТИС КФУ (Весна 2015) by nzhiltsov</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">Information Retrieval</h1>
        <p class="header">Страница курса по информационному поиску в Высшей Школе ИТИС КФУ</p>
      </header>
      <section>
        <h3>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Введение в информационный поиск (Весна 2015)</h3>

<p>На данной странице приведены основные материалы, которые помогут успешно подготовиться к практическим заданиям и экзамену.</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Преподаватели</h3>

<p>Никита Жильцов (<a href="https://github.com/nzhiltsov" class="user-mention">@nzhiltsov</a>) - лекции<br/>Никита Мингазов (<a href="https://github.com/nmingazov" class="user-mention">@nmingazov</a>) - практика</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Слайды</h3>

<p>
<ol><li>Лекция 1: Основы информационного поиска, структура инвертированного индекса [<a href="http://slides.com/nikitazhiltsov/ir-course-lecture-1-basics?token=9Qi8EKAD4J4vHZyjzZzDmyPqmgQr">Слайды</a>]</li>
<li>Лекция 2: Алгоритмы индексирования, сжатие индекса [<a href="http://slides.com/nikitazhiltsov/ir-course-lecture-2-index-construction-compression?token=fZDdinE-">Слайды</a>]</li>
<li>Лекция 3: Ранжирование в векторной модели документа [<a href="http://slides.com/nikitazhiltsov/ir-course-lecture-3-vector-space-model">Слайды</a>]</li>
<li>Лекция 4: Вероятностные модели поиска и языковое моделирование [<a href="http://slides.com/nikitazhiltsov/deck">Слайды</a>]</li>
</ol>

<p>
<ol><li>Практика 1: Знакомство с Apache Solr [<a href="http://slides.com/stdfx/ir-practice-1">Слайды</a>]</li>
<li>Практика 2: Конфигурация Apache Solr [<a href="http://slides.com/stdfx/ir-practice-2">Слайды</a>]</li>
</ol>
</p>
</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Тестовые коллекции</h3>

<ul>
<li><a href="http://www.search-engines-book.com/collections/">Search Engines: Information Retrieval in Practice</a></li>
<li><a href="https://dumps.wikimedia.org/">Снэпшоты Википедии</a></li>
<li>РОМИП: <a href="https://yadi.sk/d/2hOwSdv9ETqVK">коллекция By.web</a>, <a href="http://romip.ru/relevance-tables/ru/index.html">таблицы релевантности</a>, <a href="http://romip.ru/ru/collections/format-docs.html">описание формата</a></li>
</ul>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Практические задания</h3>

<p>
<ol><li>Необходимо составить списки стоп-слов на основе статистики терминов в коллекции по трем разным коллекциям документов. Стоп-словами будут считаться 5% самых частотных и 5% наименее частотных (по документной частоте) терминов из индекса. Предобработка коллекции должна включать основные операции, такие как перевод в нижний регистр и стемминг. </li>
<li>Для данной коллекции построить графики распределений, иллюстрирующие законы Ципфа и Хипса. Графики должны содержать кривые, построенные по коллекции, и прямые, параметризуемые этими законами и построенными с помощью метода наименьших квадратов.</li>
<li>Реализовать сжатие словаря фронтальным кодированием. В реализуемой структуре данных для каждого термина должны храниться значения документной частоты, указатели на списки словопозиций, указатели терминов. Необходимо реализовать поиск термина (term lookup): по данному термину найти его документную частоту. Апробировать на тестовой коллекции.</li>
<li>Реализовать сжатие файла словопозиций кодированием переменной длины (variable byte encoding). Апробировать на тестовой коллекции.</li>
<li>Реализовать вариант функции ранжирования tf-idf - модель с опорной нормировкой (pivoted document length normalization). <img src="pivoted_document_length_model.png" alt="модель с опорной нормировкой" width="80%"/>, где D - документ, Q - запрос, tf(t,D) - частота термина t в документе D, |D| - длина документа D, avdl - средняя длина документа, tf(t,Q) - частота термина t в запросе, N - количество документов в коллекции, df(t) - документная частота термина t, s - параметр в диапазоне [0,1]. Апробировать на тестовой коллекции.</li> 
<li>Реализовать варианты функции ранжирования tf-idf с разным масштабированием документной частоты. См. рис.<br/> <img src="document_frequency_scaling.png" alt="масштабирование документной частотности" width=50%"/><br/>Апробировать на тестовой коллекции.</li>
<li>Реализовать языковую модель, основанную на линейной интерполяции (сглаживание Елинека-Мерсера), при которой вероятность сгенерировать термин t из документа d оценивается как смесь (линейная комбинация) распределений вероятностей термина по документу и по коллекции. См. формулу.<br/> <img src="jelinek_mercer_smoothing.png" alt="языковая модель, основанная на линейной интерполяции" width="70%"/><br/>Апробировать на тестовой коллекции.</li>
<li>Реализовать подсчет основных мер оценивания: точность на уровне k (P@k), макроусредненная средняя точность на уровне k (MAP@k), <a href="http://en.wikipedia.org/wiki/Mean_reciprocal_rank">mean reciprocal rank</a> (MRR). Протестировать результаты с помощью коллекции CACM (см. п. "Тестовые коллекции") и оценок релевантности (relevance judgments), генерируя поисковую выдачу случайным образом смешивая релевантные и неоцененные результаты (эмуляция некоторой функции ранжирования). Сравнить полученные оценки с результатами инструмента оценивания от TREC: <a href="http://trec.nist.gov/trec_eval/">trec_eval</a>.</li>
<li>Провести оптимизацию параметра регуляризации (C) линейной модели обучения ранжированию <a href="http://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html">SVM-rank</a> (linear kernel) в схеме пятиблочного скользящего контроля (5-fold cross validation). В качестве тестовой коллекции взять CACM (см. п. "Тестовые коллекции") с оценками релевантности. В качестве целевой меры - усредненную среднюю точность (MAP@k). Привести оценки качества поиска для разных параметров с макроусреднением по 5 блокам. Меры оценивания можно считать с помощью инструмента <a href="http://trec.nist.gov/trec_eval/">trec_eval</a>.</li>
</ol>
<img src="tasks_for_students.png" alt="распределение задач" width="80%"/>
</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Оценка</h3>

<table style="width:100%">
<tr>
    <th>Части курса</th>
    <th>Баллы</th> 
    <th>Дата сдачи</th>
  </tr>
  <tr>
    <td>Практические задания</td>
    <td>30%</td>		
    <td>26 марта (Продлено!)</td>
  </tr>
  <tr>
    <td>Проект</td>
    <td>20%</td>		
    <td>26 марта</td>
  </tr>
  <tr>
    <td>Экзамен</td>
    <td>50%</td>		
    <td>TBA</td>
  </tr>
</table>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Рекомендованная литература</h3>

<p>
<ol>
<li>К. Маннинг, П. Рагхаван, Х.Шютце. Введение в информационный поиск. Пер. с англ. - М.: ООО "И.Д. Вильямс", 2011. - 528 с. (Основной учебник).</li>
<li>Tie-Yan Liu. Learning to Rank for Information Retrieval. Springer, 2011.</li>
</p>	

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Идеи для проектов</h3>

<h4>Приложения</h4>

<ol><li><a href="https://ru.wikipedia.org/wiki/%D0%92%D0%B5%D1%80%D1%82%D0%B8%D0%BA%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%BF%D0%BE%D0%B8%D1%81%D0%BA">Вертикальный поиск</a> по <a href="http://kpfu.ru">сайту нашего университета</a>: подразделение (см. <a href="http://kpfu.ru/structure">список</a>), сотрудники (<a href="http://kpfu.ru/main?p_id=10076&p_lang=&p_pub_type=20&p_type=9">пример страницы</a>), конкурсы/программы/гранты (см. <a href="http://kpfu.ru/international/proekty-i-granty/otkrytye-konkursy/arhiv">страницу</a>). Система должна автоматически определять тип запрашиваемой страницы в запросе по ключевым словам. Пример эвристики - если в запросе упоминается имя, возвращать релевантные страницы о сотруднике (а не произвольные страницы, на которых упоминается данное имя). </li>
<li>Отслеживание товара (задается ключевыми словами, например, "телевизор большая диагональ") в агрегаторе <a href="https://tech.yandex.ru/market/content/">Яндекс.Маркет.</a> Индекс периодически обновляется. Учесть свежесть результатов при ранжировании.</li>
<li>Поиск по пабликам КФУ и ИТИСа ВКонтакте: по упоминаниям людей в сообщениях, авторам сообщений и тексту сообщения (например, "петя иванов студвесна"). Можно использовать <a href="https://vk.com/dev/openapi">API ВКонтакте</a>. Выделять термины в запросе, обозначающие имя, и придать им больший вес в ранжирующей функции.</li>
<li>Поиск твитов (см. <a href="https://dev.twitter.com/rest/public">Twitter API</a>). Придумать новую ранжирующую функцию, которая бы учитывала: появление ключевого слова как обычного слова, упоминания пользователя и в виде хэштэга; нормализацию по длине. Кроме того, обратить внимание на предобработку - разбиение на лексемы.</li>
<li>Поиск упоминаний компаний в новостях. Можно взять RSS ленту с пресс-релизами о компаниях, например, <a href="http://firrma.ru/data/rss/">Firrma</a>. На стадии индексирования компании можно выделять из некоторого готового словаря (возможно, с алиасами - эквивалентными наименованиями, например, "Российские технологии"="Ростех"). В поисковом интерфейсе вводятся ключевые слова, обозначающие компанию, и, возможно, уточняющие термины (например, "ростех выручка"). Система возвращает релевантные новости. Учесть различное взвешивание терминов в запросе.</li>

</ol>	


<h4>Темы исследований</h4>
<ol>
<li>Провести сравнительную экспериментальную оценку различных ранжирующих функций на основе разных вариантов взвешивания TF-IDF для некоторых тестовых коллекций (как минимум две). Взять в качестве основы (baseline) - классическую схему взвешивания TF-IDF. Привести значения основных мер оценивания (MAP@100, P@10, P@20, MRR, NDCG@100) и процент относительного улучшения по сравнению с основой. Посчитать статистическую значимость по тесту Фишера. Сделать выводы.</li>
<li>Провести аналогичное исследование (см. 1). Сравнить только BM25 и query likelihood language model (Dirichlet smoothing). Оптимизировать параметры модели BM25 в схеме пятиблочного скользящего контроля. Сделать выводы.</li>
<li>Придумать статические и динамические характеристики документов (см. Лекция 3). Исследовать их значимость (в смысле качества поисковых результатов) по схеме leave-one-out для модели обучения ранжированию SVM-rank. Привести результаты, как минимум, на двух тестовых коллекциях. Сделать выводы.</li>
</ol>
  </body>
</html>
