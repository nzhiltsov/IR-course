<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Курс по информационному поиску ИТИС КФУ (Весна 2015) by nzhiltsov</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">Information Retrieval</h1>
        <p class="header">Страница курса по информационному поиску в Высшей Школе ИТИС КФУ</p>
      </header>
      <section>
        <h3>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Введение в информационный поиск (Весна 2015)</h3>

<p>На данной странице приведены основные материалы, которые помогут успешно подготовиться к практическим заданиям и экзамену.</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Преподаватели</h3>

<p>Никита Жильцов (<a href="https://github.com/nzhiltsov" class="user-mention">@nzhiltsov</a>) - лекции<br/>Никита Мингазов (<a href="https://github.com/nmingazov" class="user-mention">@nmingazov</a>) - практика</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Слайды</h3>

<p>
<ol><li>Лекция 1: Основы информационного поиска, структура инвертированного индекса [<a href="http://slides.com/nikitazhiltsov/ir-course-lecture-1-basics?token=9Qi8EKAD4J4vHZyjzZzDmyPqmgQr">Слайды</a>]</li>
<li>Лекция 2: Алгоритмы индексирования, сжатие индекса [<a href="http://slides.com/nikitazhiltsov/ir-course-lecture-2-index-construction-compression?token=fZDdinE-">Слайды</a>]</li>
<li>Лекция 3: Ранжирование в векторной модели документа [<a href="http://slides.com/nikitazhiltsov/ir-course-lecture-3-vector-space-model">Слайды</a>]</li>
</ol>
</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Тестовые коллекции</h3>

<a href="http://www.search-engines-book.com/collections/">Search Engines: Information Retrieval in Practice</a>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Практические задания</h3>

<p>
<ol><li>Необходимо составить списки стоп-слов на основе статистики терминов в коллекции по трем разным коллекциям документов. Стоп-словами будут считаться 5% самых частотных и 5% наименее частотных (по документной частоте) терминов из индекса. Предобработка коллекции должна включать основные операции, такие как перевод в нижний регистр и стемминг. </li>
<li>Для данной коллекции построить графики распределений, иллюстрирующие законы Ципфа и Хипса. Графики должны содержать кривые, построенные по коллекции, и прямые, параметризуемые этими законами и построенными с помощью метода наименьших квадратов.</li>
<li>Реализовать сжатие словаря фронтальным кодированием. В реализуемой структуре данных для каждого термина должны храниться значения документной частоты, указатели на списки словопозиций, указатели терминов. Необходимо реализовать поиск термина (term lookup): по данному термину найти его документную частоту. Апробировать на тестовой коллекции.</li>
<li>Реализовать сжатие файла словопозиций кодированием переменной длины (variable byte encoding). Апробировать на тестовой коллекции.</li>
<li>Реализовать вариант функции ранжирования tf-idf - модель с опорной нормировкой (pivoted document length normalization). <img src="pivoted_document_length_model.png" alt="модель с опорной нормировкой" width="80%"/>, где D - документ, Q - запрос, tf(t,D) - частота термина t в документе D, |D| - длина документа D, avdl - средняя длина документа, tf(t,Q) - частота термина t в запросе, N - количество документов в коллекции, df(t) - документная частота термина t, s - параметр в диапазоне [0,1]. Апробировать на тестовой коллекции.</li> 
<li>Реализовать варианты функции ранжирования tf-idf с разным масштабированием документной частоты. См. рис.<br/> <img src="document_frequency_scaling.png" alt="масштабирование документной частотности" width=50%"/><br/>Апробировать на тестовой коллекции.</li>
<li>Реализовать языковую модель, основанную на линейной интерполяции (сглаживание Елинека-Мерсера), при которой вероятность сгенерировать термин t из документа d оценивается как смесь (линейная комбинация) распределений вероятностей термина по документу и по коллекции. См. формулу.<br/> <img src="jelinek_mercer_smoothing.png" alt="языковая модель, основанная на линейной интерполяции" width="70%"/><br/>Апробировать на тестовой коллекции.</li>
<li>Реализовать подсчет основных мер оценивания: точность на уровне k (P@k), макроусредненная средняя точность на уровне k (MAP@k), <a href="http://en.wikipedia.org/wiki/Mean_reciprocal_rank">mean reciprocal rank</a> (MRR). Протестировать результаты с помощью коллекции CACM (см. п. "Тестовые коллекции") и оценок релевантности (relevance judgments), генерируя поисковую выдачу случайным образом смешивая релевантные и неоцененные результаты (эмуляция некоторой функции ранжирования). Сравнить полученные оценки с результатами инструмента оценивания от TREC: <a href="http://trec.nist.gov/trec_eval/">trec_eval</a>.</li>
<li>Провести оптимизацию параметра регуляризации (C) линейной модели обучения ранжированию <a href="http://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html">SVM-rank</a> (linear kernel) в схеме пятиблочного скользящего контроля (5-fold cross validation). В качестве тестовой коллекции взять CACM (см. п. "Тестовые коллекции") с оценками релевантности. В качестве целевой меры - усредненную среднюю точность (MAP@k). Привести оценки качества поиска для разных параметров с макроусреднением по 5 блокам. Меры оценивания можно считать с помощью инструмента <a href="http://trec.nist.gov/trec_eval/">trec_eval</a>.</li>
</ol>
<img src="tasks_for_students.png" alt="распределение задач" width="80%"/>
</p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Оценка</h3>

<table style="width:100%">
<tr>
    <th>Части курса</th>
    <th>Баллы</th> 
    <th>Дата сдачи</th>
  </tr>
  <tr>
    <td>Практические задания</td>
    <td>30%</td>		
    <td>26 марта (Продлено!)</td>
  </tr>
  <tr>
    <td>Проект</td>
    <td>20%</td>		
    <td>26 марта</td>
  </tr>
  <tr>
    <td>Экзамен</td>
    <td>50%</td>		
    <td>TBA</td>
  </tr>
</table>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Рекомендованная литература</h3>

<p>
<ol>
<li>К. Маннинг, П. Рагхаван, Х.Шютце. Введение в информационный поиск. Пер. с англ. - М.: ООО "И.Д. Вильямс", 2011. - 528 с. (Основной учебник).</li>
<li>Tie-Yan Liu. Learning to Rank for Information Retrieval. Springer, 2011.</li>
</p>		
  </body>
</html>
